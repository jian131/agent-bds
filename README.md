# ğŸ  BDS Agent - Há»‡ thá»‘ng tÃ¬m kiáº¿m BÄS vá»›i Crawl4AI

Há»‡ thá»‘ng tÃ¬m kiáº¿m báº¥t Ä‘á»™ng sáº£n tá»± Ä‘á»™ng thu tháº­p, phÃ¢n tÃ­ch vÃ  lá»c thÃ´ng tin tá»« nhiá»u nguá»“n vá»›i AI vÃ  Vector Search.

## âœ¨ TÃ­nh nÄƒng chÃ­nh

- **âš¡ Crawl4AI Integration**: Thu tháº­p dá»¯ liá»‡u siÃªu nhanh vá»›i Playwright + CSS Selectors
- **ğŸŒ Multi-source crawling**: Batdongsan.com.vn, Mogi, Alonhadat, Facebook Groups, Google Search
- **ğŸ” Smart Search Filtering**:
  - Tá»± Ä‘á»™ng parse query (giÃ¡, Ä‘á»‹a Ä‘iá»ƒm, loáº¡i BÄS)
  - Filter theo city/district vá»›i city detection
  - Price range vá»›i 30% tolerance
- **ğŸ¯ Semantic Search**: ChromaDB + Sentence-Transformers (multilingual)
- **âœ… Data Validation**: Parse vÃ  validate giÃ¡, diá»‡n tÃ­ch, sá»‘ Ä‘iá»‡n thoáº¡i, Ä‘á»‹a chá»‰
- **ğŸ“Š Backend API**: FastAPI vá»›i streaming support
- **ğŸ¨ Frontend**: Next.js 14 + Shadcn/UI

## ğŸ› ï¸ Tech Stack

| Component    | Technology                                       |
| ------------ | ------------------------------------------------ |
| Web Crawling | Crawl4AI 0.3.74 (Playwright + CSS Selectors)     |
| LLM          | Google Gemini 2.0 Flash                          |
| Vector DB    | ChromaDB + paraphrase-multilingual-MiniLM-L12-v2 |
| Backend      | FastAPI                                          |
| Database     | PostgreSQL (optional - currently degraded)       |
| Frontend     | Next.js 14 + TailwindCSS + Shadcn/UI             |
| Language     | Python 3.11+                                     |

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
bds-agent/
â”œâ”€â”€ main.py                      # Backend API entry point
â”œâ”€â”€ config.py                    # Environment config
â”œâ”€â”€ requirements.txt             # Python dependencies
â”‚
â”œâ”€â”€ agents/
â”‚   â””â”€â”€ search_agent.py          # Search orchestration agent
â”‚
â”œâ”€â”€ crawlers/
â”‚   â”œâ”€â”€ google_crawler.py        # Google Search vá»›i Gemini
â”‚   â”œâ”€â”€ platform_crawlers.py     # Batdongsan, Mogi, Alonhadat crawlers
â”‚   â”œâ”€â”€ facebook_crawler.py      # Facebook Groups crawler
â”‚   â””â”€â”€ css_selectors.py         # CSS selectors cho tá»«ng platform
â”‚
â”œâ”€â”€ parsers/
â”‚   â””â”€â”€ listing_parser.py        # Parse & validate listings
â”‚
â”œâ”€â”€ services/
â”‚   â””â”€â”€ search_service.py        # Main search service (filtering, dedup)
â”‚
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ vector_db.py             # ChromaDB wrapper
â”‚   â””â”€â”€ database.py              # PostgreSQL (optional)
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/                     # Next.js App Router
â”‚   â”œâ”€â”€ components/              # React components
â”‚   â””â”€â”€ lib/                     # Utils & API client
â”‚
â””â”€â”€ data/
    â””â”€â”€ models/                  # VectorDB models (420MB, tracked by Git LFS)
```

## ğŸš€ CÃ i Ä‘áº·t vÃ  Cháº¡y há»‡ thá»‘ng

### 1. YÃªu cáº§u há»‡ thá»‘ng

- **Python 3.11+** 
- **Node.js 18+** (cho frontend)
- **Git LFS** (Ä‘á»ƒ clone model files)
- **Google Gemini API Key** (miá»…n phÃ­ táº¡i https://aistudio.google.com/apikey)

### 2. Clone repository

```bash
# Install Git LFS (náº¿u chÆ°a cÃ³)
git lfs install

# Clone project (bao gá»“m model 420MB qua LFS)
git clone https://github.com/jian131/agent-bds.git
cd agent-bds/bds-agent
```

### 3. Setup Backend (Python)

```bash
# Táº¡o virtual environment
python -m venv venv

# Activate venv
venv\Scripts\activate      # Windows
# source venv/bin/activate # Linux/Mac

# Install dependencies
pip install -r requirements.txt

# Install Playwright browsers (cho Crawl4AI)
playwright install chromium
```

### 4. Cáº¥u hÃ¬nh mÃ´i trÆ°á»ng

```bash
# Copy file .env.example
copy .env.example .env     # Windows
# cp .env.example .env     # Linux/Mac
```

Chá»‰nh sá»­a file `.env`:

```ini
# === Google Gemini API (Báº®T BUá»˜C) ===
GOOGLE_API_KEY=your_gemini_api_key_here

# === VectorDB Settings ===
VECTORDB_ENABLED=true
VECTORDB_MODEL=paraphrase-multilingual-MiniLM-L12-v2  # Model Ä‘Ã£ cÃ³ sáºµn

# === Database (OPTIONAL - hiá»‡n táº¡i degraded) ===
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/bds_agent
# CÃ³ thá»ƒ bá» qua - há»‡ thá»‘ng váº«n cháº¡y khÃ´ng cáº§n DB

# === API Settings ===
API_HOST=0.0.0.0
API_PORT=8000
```

### 5. Cháº¡y Backend API

```bash
# Start FastAPI server
python main.py

# Hoáº·c vá»›i uvicorn
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

API sáº½ cháº¡y táº¡i: **http://localhost:8000**

Swagger docs: **http://localhost:8000/docs**

### 6. Setup Frontend (Next.js)

Má»Ÿ terminal má»›i:

```bash
cd frontend

# Install dependencies
npm install

# Cháº¡y dev server
npm run dev
```

Frontend sáº½ cháº¡y táº¡i: **http://localhost:3000**

### 7. Test há»‡ thá»‘ng

**Tá»« giao diá»‡n web:**
- Truy cáº­p http://localhost:3000
- Nháº­p query: `chung cu 3 ty thanh xuan ha noi`
- Xem káº¿t quáº£ real-time

**Tá»« API:**
```bash
# Test health
curl http://localhost:8000/health

# Test search
curl "http://localhost:8000/api/v1/search?query=chung%20cu%202%20ty%20cau%20giay"
```

**Tá»« Python:**
```python
import requests

response = requests.get(
    "http://localhost:8000/api/v1/search",
    params={"query": "chung cu 5 ty ha noi"}
)
print(response.json())
```

## ğŸ“– API Endpoints

### Search API

**GET** `/api/v1/search`

Query Parameters:
- `query` (required): Search query (VD: "chung cu 2 ty cau giay")
- `max_results` (optional): Sá»‘ lÆ°á»£ng káº¿t quáº£ tá»‘i Ä‘a (default: 50)

Response:
```json
{
  "listings": [
    {
      "id": "abc123",
      "title": "BÃ¡n cÄƒn há»™ 2PN táº¡i Cáº§u Giáº¥y",
      "price_text": "2,5 tá»·",
      "price_number": 2500000000,
      "area_text": "75mÂ²",
      "area_m2": 75.0,
      "location": {
        "address": "ÄÆ°á»ng Tráº§n Duy HÆ°ng",
        "district": "Cáº§u Giáº¥y",
        "city": "HÃ  Ná»™i"
      },
      "contact": {
        "name": "Chá»§ nhÃ ",
        "phones": ["0912345678"]
      },
      "images": ["url1", "url2"],
      "source_url": "https://...",
      "source_platform": "batdongsan.com.vn"
    }
  ],
  "total": 15,
  "query_parsed": {
    "city": "HÃ  Ná»™i",
    "district": "cau giay",
    "price_min": 1.6,
    "price_max": 2.4,
    "property_type": "apartment"
  }
}
```

### Streaming Search API

**GET** `/api/v1/search/stream`

Server-Sent Events (SSE) endpoint cho real-time updates.

Event types:
- `status`: ThÃ´ng bÃ¡o tiáº¿n trÃ¬nh
- `result`: Tá»«ng listing
- `complete`: HoÃ n thÃ nh

### Health Check

**GET** `/health`

```json
{
  "status": "healthy",
  "service": "bds-agent",
  "version": "2.0",
  "llm": "ok",
  "database": "degraded"
}
```

## ğŸ” Search Query Examples

Há»‡ thá»‘ng tá»± Ä‘á»™ng parse query tiáº¿ng Viá»‡t:

| Query                              | Parsed                                                  |
| ---------------------------------- | ------------------------------------------------------- |
| "chung cu 2 ty cau giay"           | city=HN, district=Cau Giay, price=1.6-2.4 tá»·            |
| "nha rieng thanh xuan 5 ty"        | city=HN, district=Thanh Xuan, price=4-6 tá»·, type=house |
| "can ho quan 7 hcm 3-4 ty"         | city=HCM, district=Q7, price=3-4 tá»·                     |
| "biet thu da nang duoi 10 ty"      | city=Da Nang, price=0-10 tá»·, type=villa                |
| "chung cu ha noi"                  | city=HN, type=apartment                                 |

## ğŸ“Š Listing Data Structure

Má»—i listing cÃ³ cáº¥u trÃºc:

```python
{
    "id": str,                    # Unique ID (MD5 hash)
    "title": str,                 # TiÃªu Ä‘á»
    "price_text": str,            # GiÃ¡ dáº¡ng text "2,5 tá»·"
    "price_number": int,          # GiÃ¡ dáº¡ng sá»‘ (VND)
    "area_text": str,             # Diá»‡n tÃ­ch text "75mÂ²"
    "area_m2": float,             # Diá»‡n tÃ­ch sá»‘
    "location": {
        "address": str,           # Äá»‹a chá»‰ Ä‘áº§y Ä‘á»§
        "ward": str,              # PhÆ°á»ng/xÃ£
        "district": str,          # Quáº­n/huyá»‡n
        "city": str              # ThÃ nh phá»‘
    },
    "contact": {
        "name": str,              # TÃªn ngÆ°á»i liÃªn há»‡
        "phones": List[str],      # Danh sÃ¡ch SÄT
        "zalo": List[str],        # Zalo IDs
        "facebook": List[str],    # Facebook profiles
        "email": List[str]        # Emails
    },
    "images": List[str],          # URLs áº£nh
    "source_url": str,            # URL gá»‘c
    "source_platform": str,       # Platform name
    "property_type": str,         # Loáº¡i BÄS
    "bedrooms": int,              # Sá»‘ phÃ²ng ngá»§
    "bathrooms": int,             # Sá»‘ phÃ²ng táº¯m
    "description": str,           # MÃ´ táº£
    "scraped_at": datetime,       # Thá»i gian crawl
    "posted_at": str             # Thá»i gian Ä‘Äƒng (náº¿u cÃ³)
}
```

## ğŸ¯ Smart Filtering

Há»‡ thá»‘ng filter listings dá»±a trÃªn:

### 1. Price Filtering
- Parse giÃ¡ tá»« text: "2,5 tá»·", "500 triá»‡u", "3.5 tá»·"
- 30% tolerance: TÃ¬m 3 tá»· â†’ filter 2.1-3.9 tá»·
- Cho phÃ©p "GiÃ¡ thá»a thuáº­n" (negotiate)

### 2. Location Filtering
- **City matching**: "HÃ  Ná»™i", "HCM", "ÄÃ  Náºµng", v.v.
- **District matching**: Há»— trá»£ cÃ³/khÃ´ng dáº¥u
  - "cau giay" = "cáº§u giáº¥y" = "Cáº§u Giáº¥y"
  - "thanh xuan" = "thanh xuÃ¢n"
- **Auto-detect city** tá»« location text
  - "BÃ¬nh DÆ°Æ¡ng" â†’ filter out khi search HN
  - "Quáº­n 7" â†’ auto-detect HCM

### 3. Property Type
- Chung cÆ° / CÄƒn há»™ â†’ `apartment`
- NhÃ  phá»‘ / NhÃ  riÃªng â†’ `house`
- Biá»‡t thá»± â†’ `villa`
- Äáº¥t / Äáº¥t ná»n â†’ `land`

## ğŸ—ï¸ Architecture

### Search Flow

```
User Query
    â†“
Query Parser (extract city, district, price, type)
    â†“
URL Generator (platform-specific URLs)
    â†“
Parallel Crawling (Crawl4AI + Playwright)
    â”œâ”€ Batdongsan.com.vn
    â”œâ”€ Mogi.vn
    â”œâ”€ Alonhadat.com.vn
    â”œâ”€ Facebook Groups
    â””â”€ Google Search
    â†“
Parser & Validator (clean + validate)
    â†“
Filter by Criteria (price, location, type)
    â†“
Deduplication (by ID hash)
    â†“
VectorDB Storage (optional)
    â†“
Return Results
```

### Crawling Mechanism

**Crawl4AI Features:**
- Async Playwright browser automation
- CSS selector-based extraction
- Auto-scroll and pagination
- Proxy rotation support
- Cache management

**Selectors per Platform:**
```python
# Batdongsan.com.vn
LISTING_SELECTOR = ".re__card-info"
TITLE = ".re__card-title"
PRICE = ".re__card-config-price"
LOCATION = ".re__card-location"

# Mogi.vn
LISTING_SELECTOR = ".property-item"
TITLE = ".property-title"
...
```

## ğŸ”§ Advanced Configuration

### VectorDB Settings

```python
# storage/vector_db.py
VECTORDB_CONFIG = {
    "collection_name": "bds_listings",
    "model_name": "paraphrase-multilingual-MiniLM-L12-v2",
    "dimension": 384,
    "distance_metric": "cosine"
}
```

### Crawling Settings

```python
# config.py
CRAWL_SETTINGS = {
    "timeout": 30,              # Request timeout (seconds)
    "max_retries": 3,           # Max retry attempts
    "concurrent_requests": 10,  # Parallel requests
    "delay_between": 1.0,       # Delay between requests
    "user_agent_rotate": True,  # Rotate user agents
}
```

### Price Range by City

```python
# services/search_service.py
PRICE_MULTIPLIERS = {
    "hÃ  ná»™i": {"min": 0.8, "max": 1.2},
    "há»“ chÃ­ minh": {"min": 0.9, "max": 1.3},
    "Ä‘Ã  náºµng": {"min": 0.7, "max": 1.1},
}
```

## ğŸ“ Development

### Add New Platform

1. **Add CSS selectors** in `crawlers/css_selectors.py`:
```python
CSS_SELECTORS["newplatform.com"] = {
    "listing": ".listing-item",
    "title": ".title",
    "price": ".price",
    ...
}
```

2. **Add platform URL generator** in `services/search_service.py`:
```python
def _generate_fallback_urls(self, query):
    # ... existing code ...
    
    # New platform
    newplatform_url = f"https://newplatform.com/search?q={query}"
    urls.append({
        "url": newplatform_url,
        "platform": "newplatform.com"
    })
```

## ğŸ Troubleshooting

### Model khÃ´ng táº£i Ä‘Æ°á»£c
```bash
# Check Git LFS
git lfs ls-files

# Re-pull LFS files
git lfs pull
```

### Crawl bá»‹ cháº·n
```python
# TÄƒng delay giá»¯a requests
DELAY_BETWEEN = 2.0

# Rotate user agents
USER_AGENT_ROTATE = True

# Sá»­ dá»¥ng proxy
PROXY_LIST = ["http://proxy1:8080", ...]
```

### VectorDB lá»—i
```bash
# XÃ³a collection vÃ  táº¡o láº¡i
rm -rf data/chroma_db/

# Hoáº·c disable VectorDB
VECTORDB_ENABLED=false
```

### Database khÃ´ng káº¿t ná»‘i
```ini
# System váº«n cháº¡y vá»›i degraded DB
# Check logs
tail -f logs/app.log
```

## âš ï¸ LÆ°u Ã½ vá» Model

**Model Ä‘Æ°á»£c commit vÃ o Git vÃ¬:**
- âœ… TrÃ¡nh pháº£i download má»—i láº§n setup (420MB)
- âœ… Sá»­ dá»¥ng Git LFS Ä‘á»ƒ quáº£n lÃ½ file lá»›n
- âœ… Model nhá» vÃ  cáº§n thiáº¿t cho VectorDB

**Náº¿u khÃ´ng muá»‘n model trong repo:**
1. XÃ³a folder `data/models/`
2. Download runtime:
```bash
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')"
```

**Git LFS Configuration:**
```bash
# .gitattributes
*.bin filter=lfs diff=lfs merge=lfs -text
*.json filter=lfs diff=lfs merge=lfs -text
```

Files tracked by LFS:
- `pytorch_model.bin` (420MB)
- `tokenizer.json` (2.3MB)

## ğŸ“„ License

MIT License

## ğŸ¤ Contributing

1. Fork repo
2. Create feature branch: `git checkout -b feature/new-feature`
3. Commit changes: `git commit -m "Add new feature"`
4. Push: `git push origin feature/new-feature`
5. Open Pull Request

## ğŸ“ Contact

- GitHub: [jian131/agent-bds](https://github.com/jian131/agent-bds)
- Issues: [agent-bds/issues](https://github.com/jian131/agent-bds/issues)

---

Made with â¤ï¸ by BDS Agent Team
